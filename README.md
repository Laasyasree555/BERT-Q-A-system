# ğŸ§  BERT-Based Question Answering System

A transformer-powered Question Answering (QA) system built using **BERT** and deployed as an interactive **Streamlit web application**.

---

## ğŸš€ Live Demo  
ğŸ‘‰ **Try the QA System Here:**  
(https://bert-q-a-system-dwtpjjdeqjkzuop3amgtlq.streamlit.app/]

---

Front Page & Output/Result
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/8b873c34-a2bb-43a6-b831-6c5a6d9764a9" />


## ğŸ“Œ Project Overview  
This project fine-tunes a **BERT model** for span-based question answering using the **SQuAD dataset**.  
A Streamlit UI allows users to input a paragraph and ask questions, receiving:
- Extracted answer  
- Confidence score  
- Real-time prediction  

---

## ğŸ”§ Tech Stack  
- **Python**
- **PyTorch**
- **HuggingFace Transformers**
- **BERT (QA Head)**
- **SQuAD Dataset**
- **Tokenizers**
- **Streamlit**
- **Google Colab** (model training)

---

## âœ¨ Features  
- Context-aware Q/A using BERT  
- Extractive answer generation  
- Real-time inference pipeline  
- Confidence scoring  
- Simple & responsive Streamlit interface  
- Hosted permanently on Streamlit Cloud  

---

## ğŸ“‚ Repository Structure  
```
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ qa_model/               # Fine-tuned model folder (optional)
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ README.md               # Documentation
```

---

## â–¶ï¸ Running Locally  
Clone the repo and install the dependencies:

```bash
pip install -r requirements.txt
```

Launch the Streamlit app:

```bash
streamlit run app.py
```

---

## ğŸ“« Contact  
For improvements or suggestions, feel free to open an issue or pull request.

---

